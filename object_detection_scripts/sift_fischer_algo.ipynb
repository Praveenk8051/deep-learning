{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install yael"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description based on Fischer Vectors\n",
    "* We have the image files and corresponding SIFT files\n",
    "* Global Fisher vector is calculated for each image using SIFTs of the images\n",
    "* Later, L2 distance between FVs is good to approximate the similarity of the contents of the images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "* list of available images\n",
    "* load the SIFTs for these images\n",
    "* Next we sample the descriptors to reduce their dimensionality by PCA and computing a GMM. For a GMM of size k (letâ€™s set it to 64), we need about 1000*k training descriptors\n",
    "\n",
    "    * make a big matrix with all image descriptors\n",
    "    * choose n_sample descriptors at random\n",
    "    * until now sample was in uint8. Convert to float32\n",
    "    * compute mean and covariance matrix for the PCA\n",
    "    * compute PCA matrix and keep only 64 dimensions\n",
    "        sort by increasing eigenvalue\n",
    "        eigenvectors for the 64 last eigenvalues\n",
    "    * transform sample with PCA (note that numpy imposes line-vectors,# so we right-multiply the vectors)\n",
    "    * train GMM (The FV computation relies on a training where a Gaussian Mixture Model (GMM) is fitted to a set of \n",
    "        representative local descriptors. For simplicity, we are going to use the descriptors of the database we   index.)\n",
    "        \n",
    "* The gmm is a tuple containing the a-priori weights per mixture component, the mixture centres and the diagonal of the component covariance matrices (the model assumes a diagonal matrix, otherwise the descriptor would be way too long).\n",
    "\n",
    "*  The next stage is to encode the SIFTs into one vector per image. We choose to include only the derivatives     w.r.t. mu in the FV, which results in a FV of size k * 64\n",
    "    * apply the PCA to the image descriptor\n",
    "    * compute the Fisher vector, using only the derivative w.r.t mu\n",
    "    * make one matrix with all FVs\n",
    "    * normalizations are done on all descriptors at once\n",
    "    * power-normalization\n",
    "    * L2 normalize\n",
    "    * handle images with 0 local descriptor (100 = far away from \"normal\" images)\n",
    "    \n",
    "* Now the FV can be used to compare images, so we compute for each query image the nearest images in the matrix(image_fvs).\n",
    "    * get the indices of the query images (the subset of images that end in \"00\")\n",
    "    * corresponding descriptors\n",
    "    * get the 8 nearest neighbours for all query images in the image_fvs array\n",
    "   \n",
    "* mAP performance for the search\n",
    "    * collect the positive results in the dataset\n",
    "    * the positives have the same prefix as the query image\n",
    "    * ranks of positives. We skip the result #0, assumed to be the query image\n",
    "    * accumulate trapezoids with this basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief outline of fisher vectors\n",
    "\n",
    "#### Vocabulary learning with GMM:\n",
    "* Sample many features from input images.\n",
    "* Fit a Gaussian Mixture Model on those features.\n",
    "* The result is a vocabulary of dominant features in the image, and their distributions.\n",
    "\n",
    "#### Image representation based on the vocabulary:\n",
    "* Measure the expectation of the difference and distance of the image features, from each Gaussian distrubution, using the likelihood a feature belongs to certain gaussian.\n",
    "* Concatenate the resulting vector for each vocabulary word, into one large descriptor vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
